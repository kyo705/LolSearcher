# Lolsearcher
롤 전적 검색 사이트 프로젝트
=============
-----------------------------------------
롤 전적 검색 사이트란??
-----------------------------------------

롤(League Of Legend) 게임 서버에서 OPEN API로 제공되는 유저의 게임 데이터들(랭킹 점수, 게임 횟수, 상세 게임 정보 등)을 수집하고 가공하여 클라이언트에게 제공하는 사이트입니다.

프로젝트 깃 브런치
-----------------------------------------
> - **main** — 실제 메인 브런치(완성본)
> - **develop** — 다음 버전을 위한 개발 브런치(테스트용)

프로젝트 커밋 메시지 카테고리
-----------------------------------------
> - [INITIAL] — repository를 생성하고 최초에 파일을 업로드 할 때
> - [ADD] — 신규 파일 추가
> - [UPDATE] — 코드 변경이 일어날때
> - [REFACTOR] — 코드를 리팩토링 했을때
> - [FIX] — 잘못된 링크 정보 변경, 필요한 모듈 추가 및 삭제
> - [REMOVE] — 파일 제거
> - [STYLE] — 디자인 관련 변경사항


프로젝트 내 적용 기술
-----------------------------------------
> - 백 앤드
>   - 언어 : Java
>   - 프레임 워크 : SpringBoot, Spring MVC, Spring Security
>   - 빌드 관리 툴 : Gradle
>   - REST API 수집 : WebClient
>   - ORM : JPA(Hibernate)
>   -  DBMS :
>      - 실제 서버 환경 : MariaDB
>      - 테스트 환경 : h2
> - 프론트 앤드
>   - 템플릿 엔진 : Thymeleaf

프로젝트 서버 구조
-----------------------------------------
![image](https://user-images.githubusercontent.com/89891704/188450211-fba3f0e7-4893-4f0f-8d4c-1292738ba046.png)



테스트 코드 설명서
--------------------------
테스트 환경 프레임 워크 : springboot, mockito, junit5   

 해당 프로젝트의 테스트 코드는 비지니스 로직을 중점으로 크게 두가지(단위 테스트, 통합 테스트)로 작성되었다.   
   
- 단위 테스트 : Service, Repository, RESTClient 계층 별 테스트 실시   
- 통합 테스트 : 해당 단위 테스트 계층들을 하나로 통합하여 테스트 실시

**※통합 테스트 시 주의점** : REST API 통신 계층도 통합하여 테스트하기 때문에 모든 테스트케이스를 한꺼번에 실행하면 REST API 요청 제한 횟수(2분에 100회)를 초과할 수 있음. 다시 말해, 멱등성이 유지되지 않음.

코드 소스 경로 : lolsearcher/src/test/
 
----------------------------------------

# 프로젝트 과정에서 겪은 고민들과 해결 과정

----------------------------------------

**프로젝트 설계 시 외부 JSON 데이터를 바로 파싱해서 클라이언트에게 전달하지 않고 DB에 저장한 후 클라이언트에게 데이터를 제공한 이유**   

1. 성능상의 이점 : REST API 통신은 외부와의 I/O 비용이 발생하기 때문에 가져와야하는 데이터가 많으면 많을수록 속도 측면에서 느리다. 그리고 매번 같은 데이터를 받아와 파싱하는 과정도 불필요하기 때문에 DB에 저장하는 방식이 더 적절하다고 판단하였다.   

2. 통계 데이터(승률, 모스트챔프 등..)의 서비스 제공 가능 : 매번 REST API 요청을 파싱해서 클라이언트에게 전달할 경우 통계 관련 데이터를 제공하기 어렵다. 반면, DB에 저장하면 많은 양의 데이터를 통계낼 수 있기 때문에 정확한 서비스를 클라이언트에게 제공할 수 있다. 

**갱신 버튼을 설계하여 해당 버튼을 눌러야 REST API 요청을 통해 데이터를 받아오게한 이유**

1. 성능상의 이점 : 매번 클라이언트가 닉네임을 검색할 때마다 REST 통신을 한다면 외부 서버와의 I/O 비용과 DB 서버와의 I/O 비용이 발생하면서 오히려 'JSON 데이터를 바로 파싱해 클라이언트에게 제공하는 서비스' 보다 더욱 속도가 느리게 된다. 그래서 더욱 빠른 서비스를 제공하기 위해 갱신 요청을 통해서만 REST API 통신이 이루어지도록 설계하였다.   

2. 구조적 문제 : 게임 회사에서 제공되는 REST API 요청 횟수는 2분 동안 최대 100회였다. 그래서 매번 클라이언트가 닉네임을 검색할 때마다 REST 통신을 한다면 많은 유저가 서비스를 이용할 수 없는 구조가 된다.   

**Q. 그렇다면 악의적인 사용자가 계속 갱신 요청을 시도한다면??**   

A. 충분히 발생할 수 있는 상황이다. 그래서 나는 Summoner 객체(유저 정보를 담고있는 테이블과 매핑된 Entity)의 필드 값에 '최신 갱신 요청 시간(lastRenewTimeStamp)'를 추가하여 해당 유저가 최신으로 갱신 요청한 시간이 현재 시각보다 5분 이상일 경우에만 갱신이 가능하도록 설정하였다. 그렇게 하면 브라우저가 다른 곳에서도 특정 유저에 대한 반복적인 요청은 불가능해진다. 갱신 가능 요청 시간을 5분으로 설정한 이유는 보통 한 게임의 최소시간이 5분?(게임이 '다시하기'인 경우)인 것으로 알고있다. 그래서 5분 이전에는 갱신이 반복적으로 이뤄질 필요가 없다고 판단하여서 그렇게 설정하였다.

**Q. 그렇다면 존재하지 않는 닉네임을 계속 요청할 경우라면??**

A. 나도 해당 문제를 계속 고민해보았다. 그래서 존재하지 않는 닉네임을 검색하면 해당 닉네임을 DB에 저장하여 2분동안 REST 통신말고 DB 데이터를 전달하는 방식을 고민하기도 했다. 하지만 매번 다른 닉네임을 요청할 수 있기 때문에 해당 IP를 차단하는 방법이 가장 베스트일 것 같다. 하지만 이 방법도 IP우회를 통하면 막을 수 없기 때문에 더 좋은 방법을 고민해봐야한다.

**※해당 Q&A를 쓰면서 문득 든 생각**   

현재 프로젝트의 서비스는 REST API를 DB에 저장한 후 해당 DB데이터를 가져와 클라이언트에게 제공해준다. 그런데 REST API를 바로 파싱하여 클라이언트에게 제공해주고 DB에 저장하는 로직은 독립적인 스레드를 통해 처리하면 클라이언트가 더욱 빠르게 응답을 받을 수 있을 것이라는 생각이 들었다. 그래서 새로운 방식으로 프로젝트를 수정하였다.   

**현재 문제점** : 멀티스레드 환경에서 중복 저장에 대한 최적의 해결 방안이 안 떠오름...

**기존의 멀테스레드에서 발생하는 중복 저장에 대한 상황 설명** : 클라이언트1과 클라이언트2가 특정 유저의 데이터를 동시에 갱신 요청하는 상황이 발생할 때, 클라이언트1의 트랜잭션에서 기존에 없는 데이터들을 JPA 영속성 컨텍스트에 우선 저장한다. 클라이언트2의 트랜잭션도 클라이언트1과 마찬가지로 같은 데이터들을 영속성 컨텍스트에 저장한다.(영속성 컨텍스트의 1차 캐시는 트랜잭션 별로 생성됨) 그리고 트랜잭션이 종료될 때, 커밋을 하면서 1차 캐시의 엔티티들을 DB에 저장한다. 클라이언트1의 트랜잭션이 먼저 커밋을 한다고 가정해보자. 트랜잭션1의 데이터들은 기존에 없던 데이터들이기 때문에 DB에 반영이 된다. 그 후 트랜잭션2가 커밋을 할 때, 처음 조회를 할때는 없던 데이터들이 트랜잭션1이 커밋을 하면서 DB에 데이터가 생기고 따라서 트랜잭션2는 이미 저장된 데이터들 다시 저장하려는 상황이 발생한다. 해당 상황이 중복 저장에 대한 상황이다.

기존의 프로젝트는 유저 Match 데이터를 저장하는 로직에서 중복 저장에 대한 큰 문제점이 있었다. 기존의 로직은 특정 유저의 많은 Match 데이터들을 하나의 트랜잭션에서 한번에 DB에 저장하는 로직이었다. 그런데 게임 특성상 한 Match에 10명의 유저가 이용하기 때문에 유저1의 match데이터와 유저2의 match데이터가 같은 match를 가질 수 밖에 없다. 그런데, 유저1과 유저2가 동시에 갱신 요청을 하면 특정 match의 데이터가 중복 저장되는 상황이 발생한다. 즉, 유저1의 추가되어야할 match 데이터들 100개 중 1개가 중복이 되어 나머지 99개를 롤백해야하는 상황이 발생하는 것이다.   
해당 문제를 해결하기 위해 2가지 방법을 고려하였다. 우선 첫 번째는, 매치 데이터들을 영속성 컨텍스트에 모아 한번에 DB에 저장하지 않고, 하나의 트랜잭션에 하나의 데이터만 저장하는 방식을 통해 하나의 엔티티에서 중복 저장 예외가 발생했을 때 다른 match 데이터들이 영향을 받지 않도록하는 방식이다. 그러나 해당 방식은 match 데이터 1개당 트랜잭션 1개를 필요로 하기 때문에 DB와의 I/O비용이 매우 발생하여 성능에 좋지 않다.

**DB 테이블 스키마에 대한 고민**

DB의 인덱스를 공부하면서 인덱스의 장점과 단점을 배웠다. 인덱스는 보통 B-TREE 혹은 B+TREE 자료구조를 사용해 컬럼들을 저장해놓는데 해당 자료구조는 정렬을 해놓기때문에 조회 시에는 빠르게 서치가 가능하지만 데이터를 삽입, 인덱스 컬럼 업데이트, 삭제할 때 정렬에 대한 큰 비용이 발생하기 때문에 조심해서 사용해야한다. 
현재, 해당 프로젝트에서의 Summoner 테이블에서 primaryId 컬럼을 pk설정을 통해 클러스터드 인덱스로 지정하였고, id, name 컬럼을 넌클러스터드 인덱스로 설정해주었다. 그리고 pk에 @GeneratedValue(strategy = GenerationType.IDENTITY)를 통해 테이블의 레코드가 삽입될 때마다 pk값을 오름차순으로 생성하는 구조를 만들었다. 그래서 테이블의 레코드가 삽입될 때마다 발생하는 정렬 비용을 크게 줄일 수 있었다. 그리고 Summoner 테이블에 넌클러스터드 인덱스를 2개 설정한 이유는 테이블의 레코드 갯수는 최대 유저의 수이기 때문에 대량의 레코드가 저장될 일은 없다. 반면, 조회가 빈번하기 때문에 넌클러스터드 인덱스를 설정을 통해 빠르게 조회하는 것이 좋다고 판단하여, 비지니스 로직에서 테이블을 조회할 때 필요한 조건 컬럼(id, name)을 넌클러스터드 인덱스로 설정하였다.   

Member 테이블의 pk를 복합키로 설정하고 해당 복합키의 부분키로 외래키(Match 테이블의 기본키)를 설정한 이유(Match-Member 식별관계로 설정) : 두 테이블을 조인할 때, 서로의 matchid 컬럼을 통해 조인하는데 이 때, 둘 다 pk로 설정해두면 db에서 조인 시 nested loop join을 이용해 빠르게 데이터를 조회할 수 있고, 또한 pk로 인덱스 설정이 되었기 때문에(클러스터드 인덱스) random access 부하가 없어서 대용량 데이터 처리에도 좋다. 그래서 현재 Match-Member 테이블 연관 관계 및 pk 설정, 인덱스 설정 등이 최선이라고 생각한다.   
참고로 복합키일때 인덱스 조회시 복합키 순서에 따라 range scan을 함. 예를 들어 복합키로 n1,n2,n3가 되어있을 경우 조회시 where 절에 n1이 올 경우 인덱스를 range scan하지만 where 절에 n2가 올 경우 테이블 풀스캔을 하게된다. 따라서 복합키는 pk 설정시 순서를 조회 때 필요한 컬럼 순으로 생성하는 것이 바람직하다.

기존 Match-Member 테이블 조회시 패치조인에서 batch-size로 바꾼 이유 : 비지니스 로직에서 전적을 검색할 때, 최대 100개의 Match를 가져오려하였는데 패치 조인 사용 시, 페이징 처리가 불가능하여 해당 문제를 해결하고자 batch size를 설정하여 Match 엔티티들과 Member 엔티티들을 조회하였다. 그리고 batch size를 100으로 설정해서 총 2번의 쿼리로 연관 관계 엔티티들을 다 조회하였다. 이렇게 n+1문제를 해결하였다.   

**외부 서버와의 통신 속도에 관한 문제와 해결 과정**

기존 프로젝트는 외부 서버로 부터 REST API 데이터를 받아올 때, blocking 형태로 데이터를 받아올 때까지 기다리는 구조였다. 그런데 클라이언트의 요청에 Match 관련 데이터를 최대 100번까지 받아와야 했다. 그래서 해당 프로젝트의 REST API를 받아오는데 많은 시간이 걸렸었다. 그래서 더 빠르게 데이터를 받아오고 처리할 수 있는 방법을 고민하던 중 WebClient의 non-blocking 방식으로 많은 Match 데이터들을 한 번에 처리하면 속도를 향상시킬 수 있을 것이라 판단하였다. 그러나 해당 방식으로 프로젝트를 변경하던 중 문제점이 발생했다. Non-blocking 방식으로 처리하면 몇 번째부터 429에러(too many request)가 발생했는지 모르기 때문에 처리하지 못한 데이터들을 다시 REST API 요청하는 로직을 처리할 수 없었다. 그렇다고 모든 데이터(최대 100개의 요청)를 에러 발생 여부와 관계 없이 모두 응답받는 방식으로 설계하면 속도 측면에서 비효율적이게 된다. 그래서 결론적으로 말하면, Blocking 방식과 non-blocking 방식 두가지를 다 활용하여 해당 프로젝트를 만들었다. 최신 데이터로부터 최대 20개만 REST API 통신으로 non-blocking 방식으로 데이터를 가져와 속도 측면에서 향상시켰고, 나머지 처리되지 않은 데이터들은 다른 스레드를 통해 블로킹 방식으로 외부 데이터를 가져와 DB에 저장하는 방식으로 프로젝트를 수정했다.   
blocking 방식의 장점은 아래 코드처럼 안정적으로 429에러를 처리할 수 있다. 하지만 성능적으론 속도가 느리다는 단점이 있다. 그래서 해당 방식은 클라이언트 요청 스레드에서 파생된 독립적인 스레드로 Match 데이터를 가져오는데 사용하여 클라이언트 체감 속도에는 무관하게 설계하였다.  

```java
//webClient blocking 방식
for(int i=start_index; i<matchIds.size(); ) {
	String matchId = matchIds.get(i);

	try {
		Map json = webclient.get().uri("https://asia.api.riotgames.com"
				+ "/lol/match/v5/matches/"+matchId+"?api_key="+key)
				.retrieve()
				.bodyToMono(Map.class)
				.block();

		Match match = parsingMatchJson(json);
		matches.add(match);
		i++;
	}catch(WebClientResponseException e1) {
		if(e1.getStatusCode().value()==429) {
			threadService.saveMatches(matches);
			
			try {
				System.out.println("스레드 2분 정지");
				Thread.sleep(1000*60*2+2000);
				System.out.println("스레드 다시 시작");
				matches.clear();
			} catch (InterruptedException e2) {
				e2.printStackTrace();
			}
		}
	}catch(Exception e2) {
		break;
	}
}
```

반면, non-blocking 방식은 처리 속도는 매우 빠르나, blocking방식처럼 안정적으로 예외 처리를 할 수 없다. 여기서 *안정적인 예외처리*는 아래의 코드에서처럼 논블로킹 방식의 경우 matchId에 해당하는 Match 데이터를 webClient로 요청하는데 이에 대한 응답이 순서대로 온다는 보장이 없어 어느 시점부터 429에러가 발생하는지 알 수 없다. 따라서, 요청하는 matchids의 단위를 20개로 제한하여 발생하는 에러 matchId 들은 따로 List에 저장하고 나중에 다시 실패한 matchId 목록들을 처리하도록 로직을 설계하였다.

```java
//webClient non-blocking 방식
int count = 0;
for(String matchId : matchIds) {
	if(count>=20)
		break;

	webclient.get().uri("https://asia.api.riotgames.com"+ 
	"/lol/match/v5/matches/"+matchId+"?api_key="+key)
	.retrieve()
	.bodyToMono(Map.class)
	.onErrorResume(e -> {
		if(e instanceof WebClientResponseException) {
			System.out.print(e.getMessage());
			if(((WebClientResponseException) e).getStatusCode().value() == 429) {
				fail_matchIds.add(matchId);
			}
		}

		return Mono.just(null);
	})
	.subscribe(result->{
		if(result!=null) {
			Match match = parsingMatchJson(result);
			matches.add(match);
		}
	});

	count++;
}

//webclient의 요청에 대한 응답을 다 받을때까지 기다리는 로직
while(matches.size()+fail_matchIds.size()!=count) {
	try {
		Thread.sleep(100);
	} catch (InterruptedException e) {
		e.printStackTrace();
	}
}

```
